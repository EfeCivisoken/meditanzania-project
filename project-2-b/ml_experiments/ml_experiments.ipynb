{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5029481c239ac6",
   "metadata": {},
   "source": [
    "# 1. Generate Random Data\n",
    "To do this we need to:\n",
    "1. Get the list of all healthcare facilities\n",
    "2. Use `faker` to generate user-like data for all but the open-ended survey question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T03:40:38.299937Z",
     "start_time": "2025-03-13T03:40:36.997555Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Get list of all healthcare facilities\n",
    "\n",
    "import pandas as pd\n",
    "clinics = pd.read_excel('data/clinics.xlsx')\n",
    "clinics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf584d6f1b666b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T03:41:01.290082Z",
     "start_time": "2025-03-13T03:40:38.300730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate some random feedback data\n",
    "from faker import Faker\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Constants for readability\n",
    "FEMALE = 1\n",
    "MALE = 2\n",
    "YES = 1\n",
    "NO = 2\n",
    "\n",
    "num_responses_per_clinic = 100\n",
    "responses = []\n",
    "\n",
    "for row in clinics.itertuples():\n",
    "    clinic_number = row[2]  # Assuming clinic_number is at index 2\n",
    "    for _ in range(num_responses_per_clinic):\n",
    "        gender = random.randint(1, 2)  # 1 = Female, 2 = Male\n",
    "        received_all_services_needed = random.randint(1, 4)\n",
    "        vital_signs_measured = random.randint(1, 3)\n",
    "        able_to_get_all_tests_needed = random.randint(1, 4)\n",
    "        all_medicines_needed_available = random.randint(1, 4)\n",
    "        overall_satisfaction = random.randint(1, 4)\n",
    "\n",
    "        response = {\n",
    "            'age': random.randint(1, 100),\n",
    "            'gender': gender,\n",
    "            'pregnant': np.random.choice([YES, NO], p=[0.3, 0.7]) if gender == FEMALE else NO,\n",
    "            'Facility Number': clinic_number,\n",
    "            'service_seeked': random.randint(1, 6),\n",
    "            'asked_for_consent_before_exam': random.randint(1, 3),\n",
    "            'received_all_services_needed': received_all_services_needed,\n",
    "            'why_not_received_all_services_needed': random.randint(1, 5) \n",
    "                if received_all_services_needed in [2, 3] else None,\n",
    "            'satisfied_attended_on_time': random.randint(1, 4),\n",
    "            'vital_signs_measured': vital_signs_measured,\n",
    "            'how_long_wait_to_have_vitals_measured': random.randint(1, 5) \n",
    "                if vital_signs_measured == 1 else None,\n",
    "            'how_long_wait_for_care': random.randint(1, 6),\n",
    "            'comfortable_sitting_places_while_waiting': random.randint(1, 2),\n",
    "            'practitioner_clearly_explained': random.randint(1, 2),\n",
    "            'able_to_get_all_tests_needed': able_to_get_all_tests_needed,\n",
    "            'why_not_get_all_tests_needed': random.randint(1, 4) \n",
    "                if able_to_get_all_tests_needed in [2, 3] else None,\n",
    "            'all_medicines_needed_available': all_medicines_needed_available,\n",
    "            'why_not_get_all_medicine': random.randint(1, 4) \n",
    "                if all_medicines_needed_available in [2, 3] else None,\n",
    "            'informed_how_to_take_medicine': random.randint(1, 2),\n",
    "            'satisfied_with_privacy': random.randint(1, 4),\n",
    "            'satisfied_with_cleanliness': random.randint(1, 4),\n",
    "            'addressed_treated_politely_respectfully': random.randint(1, 4),\n",
    "            'faced_issue_did_someone_listen': random.randint(1, 4),\n",
    "            'how_did_you_pay': random.randint(1, 4),\n",
    "            'overall_satisfaction': overall_satisfaction,\n",
    "            'satisfied_most': random.randint(1, 6) \n",
    "                if overall_satisfaction in [1, 2] else None,\n",
    "            'satisfied_least': random.randint(1, 6) \n",
    "                if overall_satisfaction in [3, 4] else None,\n",
    "            'other_feedback': random.randint(1, 2),\n",
    "            'feedback': fake.sentence()\n",
    "        }\n",
    "\n",
    "        responses.append(response)\n",
    "\n",
    "# Convert to DataFrame if needed\n",
    "df = pd.DataFrame(responses)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfecee67795f1ce5",
   "metadata": {},
   "source": [
    "As you can see, the `feedback` column is essentially meaningless. The hope would be to get some Swahili text and do sentiment analysis, but for now, we can disregard that column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8a95a86e66498",
   "metadata": {},
   "source": [
    "# 2. ML Experiments\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Before we do any experiments, we need to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621e058f0c9db79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T03:41:08.168857Z",
     "start_time": "2025-03-13T03:41:01.292087Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "df = clinics.copy()  # Replace with your actual file\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"ID\", \"Facility Number\", \"Official Phone Number\", \"PostalAddress\",\n",
    "                   \"OfficialEmail\", \"Website\", \"Date Opened\", \"MTUHA\", \"CTC_ID\", \"msd_id\"]\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Convert 'Not Set' and other non-numeric values to NaN\n",
    "df[['Latitude', 'Longitude']] = df[['Latitude', 'Longitude']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing numerical values (Latitude and Longitude)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "df[['Latitude', 'Longitude']] = imputer.fit_transform(df[['Latitude', 'Longitude']])\n",
    "\n",
    "# Fill missing categorical values\n",
    "categorical_columns = ['Facility Name', 'Common Name', 'Region', 'District', 'Council',\n",
    "                       'Ward', 'Ownership', 'Operating Status']\n",
    "df[categorical_columns] = df[categorical_columns].fillna(\"Unknown\")\n",
    "df[categorical_columns] = df[categorical_columns].astype(str)\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Drop first category to avoid redundancy\n",
    "encoded_columns = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Concatenate numerical and encoded categorical data\n",
    "final_df = pd.concat([df[['Latitude', 'Longitude']], encoded_df], axis=1)\n",
    "\n",
    "# Normalize the data for K-Means\n",
    "scaler = StandardScaler()\n",
    "final_df = pd.DataFrame(scaler.fit_transform(final_df), columns=final_df.columns)\n",
    "\n",
    "final_df.head() # Ready for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f4b0b8839bfd0",
   "metadata": {},
   "source": [
    "Now, we can perform the $k$-means algorithm. We first find the best $k$-value, then re-run the algorithm with that $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75090308f758dfdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T03:41:39.281543Z",
     "start_time": "2025-03-13T03:41:08.170460Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "best_k = 0\n",
    "best_score = -1\n",
    "\n",
    "for k in range(2, 11):  # Silhouette is only valid for K >= 2\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, init='k-means++')\n",
    "    cluster_labels = kmeans.fit_predict(final_df)\n",
    "    score = silhouette_score(final_df, cluster_labels)\n",
    "    \n",
    "    print(f\"K={k}, Silhouette Score={score:.4f}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "\n",
    "print(f\"Best K: {best_k} with Silhouette Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e835f7c5028eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means with the best k-value \n",
    "\n",
    "clinics_clustered = clinics.copy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_k, init='k-means++')\n",
    "cluster_labels = kmeans.fit_predict(final_df)\n",
    "\n",
    "clinics_clustered['cluster'] = cluster_labels\n",
    "clinics_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed04bb75d8e405",
   "metadata": {},
   "source": [
    "This doesn't seem to be all that helpful. What about our fake reports? Can we cluster them in some useful way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6db1eacb19e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming `responses` is your DataFrame\n",
    "responses_df = pd.DataFrame(responses)\n",
    "\n",
    "# Drop the 'feedback' column as it is not numeric\n",
    "responses_df_no_feedback_str = responses_df.drop(columns=['feedback'])\n",
    "\n",
    "# Ensure all data is numeric\n",
    "responses_df_no_feedback_str = responses_df_no_feedback_str.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "responses_df_no_feedback_str = imputer.fit_transform(responses_df_no_feedback_str)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "responses_df_no_feedback_str = scaler.fit_transform(responses_df_no_feedback_str)\n",
    "\n",
    "# Find the best k-value for K-Means\n",
    "best_k = 0\n",
    "best_score = -1\n",
    "\n",
    "for k in range(2, 11):  # Silhouette is only valid for K >= 2\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, init='k-means++')\n",
    "    cluster_labels = kmeans.fit_predict(responses_df_no_feedback_str)\n",
    "    score = silhouette_score(responses_df_no_feedback_str, cluster_labels)\n",
    "\n",
    "    print(f\"K={k}, Silhouette Score={score:.4f}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "\n",
    "print(f\"Best K: {best_k} with Silhouette Score: {best_score:.4f}\")\n",
    "\n",
    "# Run K-Means with the best k-value\n",
    "responses_clustered = responses_df.copy()\n",
    "kmeans = KMeans(n_clusters=best_k, init='k-means++')\n",
    "cluster_labels = kmeans.fit_predict(responses_df_no_feedback_str)\n",
    "responses_clustered['cluster'] = cluster_labels\n",
    "\n",
    "print(responses_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b8475d684400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means with the best k-value \n",
    "\n",
    "responses_clustered = responses_df.copy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_k, init='k-means++')\n",
    "cluster_labels = kmeans.fit_predict(responses_df_no_feedback_str)\n",
    "\n",
    "responses_clustered['cluster'] = cluster_labels\n",
    "responses_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9913908171620",
   "metadata": {},
   "source": [
    "## Anomaly Detection\n",
    "Detects outlier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea722def8cd55fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Merge the review data with the healthcare facility data\n",
    "final_df = pd.merge(clinics, df, on='Facility Number', how='left')\n",
    "\n",
    "# Drop non-numeric columns\n",
    "non_numeric_columns = ['Facility Name', 'Common Name', 'Region', 'District', 'Council', 'Ward', 'Ownership', 'Operating Status']\n",
    "final_df = final_df.drop(columns=non_numeric_columns)\n",
    "\n",
    "# Convert 'Not Set' and other non-numeric values to NaN\n",
    "final_df = final_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "final_df_imputed = imputer.fit_transform(final_df)\n",
    "\n",
    "# Create a new DataFrame with the imputed values and the original column names\n",
    "final_df = pd.DataFrame(final_df_imputed, columns=final_df.columns[:final_df_imputed.shape[1]])\n",
    "\n",
    "# Display the merged data\n",
    "print(final_df.head())\n",
    "\n",
    "# Train the Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "anomaly_labels = iso_forest.fit_predict(final_df)\n",
    "\n",
    "# Add anomaly labels to the DataFrame\n",
    "final_df['anomaly'] = anomaly_labels\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(final_df.iloc[:, 0], final_df.iloc[:, 1], c=final_df['anomaly'], cmap='coolwarm', alpha=0.5)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Anomaly Detection using Isolation Forest')\n",
    "plt.colorbar(label='Anomaly')\n",
    "plt.show()\n",
    "\n",
    "# Print all the rows that are anomalies\n",
    "anomalies = final_df[final_df['anomaly'] == -1]\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da073dbb23a9d0",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "464851902fa9f3b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:43:41.879124Z",
     "start_time": "2025-03-13T15:42:04.770232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service_seeked</td>\n",
       "      <td>0.071835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_long_wait_for_care</td>\n",
       "      <td>0.070882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>satisfied_attended_on_time</td>\n",
       "      <td>0.057416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>satisfied_with_cleanliness</td>\n",
       "      <td>0.055838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>satisfied_with_privacy</td>\n",
       "      <td>0.055681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>how_did_you_pay</td>\n",
       "      <td>0.054208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>addressed_treated_politely_respectfully</td>\n",
       "      <td>0.052702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>faced_issue_did_someone_listen</td>\n",
       "      <td>0.051619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>why_not_received_all_services_needed</td>\n",
       "      <td>0.048190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>why_not_get_all_tests_needed</td>\n",
       "      <td>0.045473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>why_not_get_all_medicine</td>\n",
       "      <td>0.044504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>able_to_get_all_tests_needed</td>\n",
       "      <td>0.044373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>received_all_services_needed</td>\n",
       "      <td>0.043813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asked_for_consent_before_exam</td>\n",
       "      <td>0.042667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all_medicines_needed_available</td>\n",
       "      <td>0.042405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>how_long_wait_to_have_vitals_measured</td>\n",
       "      <td>0.035744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vital_signs_measured</td>\n",
       "      <td>0.034955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>practitioner_clearly_explained</td>\n",
       "      <td>0.028086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comfortable_sitting_places_while_waiting</td>\n",
       "      <td>0.027699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>informed_how_to_take_medicine</td>\n",
       "      <td>0.027115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>other_feedback</td>\n",
       "      <td>0.026346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>0.024607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pregnant</td>\n",
       "      <td>0.013840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  importance\n",
       "2                             service_seeked    0.071835\n",
       "9                     how_long_wait_for_care    0.070882\n",
       "6                 satisfied_attended_on_time    0.057416\n",
       "18                satisfied_with_cleanliness    0.055838\n",
       "17                    satisfied_with_privacy    0.055681\n",
       "21                           how_did_you_pay    0.054208\n",
       "19   addressed_treated_politely_respectfully    0.052702\n",
       "20            faced_issue_did_someone_listen    0.051619\n",
       "5       why_not_received_all_services_needed    0.048190\n",
       "13              why_not_get_all_tests_needed    0.045473\n",
       "15                  why_not_get_all_medicine    0.044504\n",
       "12              able_to_get_all_tests_needed    0.044373\n",
       "4               received_all_services_needed    0.043813\n",
       "3              asked_for_consent_before_exam    0.042667\n",
       "14            all_medicines_needed_available    0.042405\n",
       "8      how_long_wait_to_have_vitals_measured    0.035744\n",
       "7                       vital_signs_measured    0.034955\n",
       "11            practitioner_clearly_explained    0.028086\n",
       "10  comfortable_sitting_places_while_waiting    0.027699\n",
       "16             informed_how_to_take_medicine    0.027115\n",
       "22                            other_feedback    0.026346\n",
       "0                                     gender    0.024607\n",
       "1                                   pregnant    0.013840"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `responses` is your DataFrame\n",
    "df = pd.DataFrame(responses)\n",
    "\n",
    "# Drop the 'feedback' and 'Facility Number' columns as they are not numeric\n",
    "df = df.drop(columns=['feedback', 'Facility Number'])\n",
    "\n",
    "# Ensure all data is numeric\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['overall_satisfaction', 'satisfied_most', 'satisfied_least', 'age'])\n",
    "y = df['overall_satisfaction']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cda2da8ff5723a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
